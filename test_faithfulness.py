"""
Test script to verify that Adaptive RAG context extraction works for faithfulness evaluation
"""
import adaptive_rag

def test_faithfulness_simulation():
    """Simulate how the evaluation framework should call AdaptiveRAG"""
    
    # Create test data
    texts = [
        'Climate change refers to long-term shifts in global temperatures and weather patterns.',
        'The main cause of climate change is the emission of greenhouse gases.',
        'Effects of climate change include rising sea levels and extreme weather.',
        'Solar panels are a renewable energy source that helps reduce carbon emissions.',
        'Fossil fuels like coal and oil contribute to greenhouse gas emissions.'
    ]
    
    print("=== Testing Adaptive RAG Faithfulness Integration ===\n")
    
    # Initialize AdaptiveRAG
    print("1. Creating AdaptiveRAG instance...")
    rag = adaptive_rag.AdaptiveRAG(texts=texts)
    
    # Test query
    query = "What causes climate change?"
    print(f"\n2. Testing query: '{query}'")
    
    # Step 1: Get context (this is what evaluation framework should do)
    print("\n3. Getting context for evaluation...")
    context = rag.get_context_for_query(query)
    print(f"   Context length: {len(context)}")
    print(f"   Context: {context[:100]}...")
    
    # Step 2: Get answer (this is what evaluation framework should do)
    print("\n4. Getting answer...")
    answer = rag.answer(query)
    print(f"   Answer: {answer}")
    
    # Step 3: Verify they use same context (this is the faithfulness check)
    print("\n5. Verifying context consistency...")
    context_from_answer = rag.last_context
    contexts_match = (context == context_from_answer)
    print(f"   Contexts match: {contexts_match}")
    print(f"   Context 1 length: {len(context)}")
    print(f"   Context 2 length: {len(context_from_answer) if context_from_answer else 0}")
    
    # Step 4: Simulate faithfulness evaluation
    print("\n6. Simulating faithfulness evaluation...")
    
    # This simulates what your evaluation framework should do:
    # Check if the answer is faithful to the retrieved context
    if "greenhouse gas" in answer.lower() and "greenhouse gas" in context.lower():
        faithfulness_score = 1.0
        print("   ‚úÖ High faithfulness: Answer mentions greenhouse gases, context contains greenhouse gases")
    elif len(context.strip()) == 0:
        faithfulness_score = 0.0
        print("   ‚ùå Zero faithfulness: No context provided")
    else:
        faithfulness_score = 0.5
        print("   ‚ö†Ô∏è Medium faithfulness: Some alignment but not perfect")
    
    print(f"   Simulated faithfulness score: {faithfulness_score}")
    
    # Step 5: Test multiple queries to see variation
    print("\n7. Testing multiple queries for faithfulness variation...")
    
    test_queries = [
        "What are the effects of climate change?",
        "How do solar panels work?",
        "What is the capital of Mars?",  # Should get low faithfulness
    ]
    
    for test_query in test_queries:
        print(f"\n   Query: {test_query}")
        test_context = rag.get_context_for_query(test_query)
        test_answer = rag.answer(test_query)
        
        # Simple faithfulness check
        if len(test_context.strip()) == 0:
            score = 0.0
        elif "don't know" in test_answer.lower():
            score = 1.0  # Faithful to say "don't know" when no context
        elif any(word in test_answer.lower() for word in test_context.lower().split()[:10]):
            score = 0.8
        else:
            score = 0.3
        
        print(f"      Context length: {len(test_context)}")
        print(f"      Answer: {test_answer[:50]}...")
        print(f"      Estimated faithfulness: {score}")
    
    print("\n=== Test Complete ===")
    print("\nüîç DIAGNOSIS:")
    print("‚úÖ AdaptiveRAG context extraction is working correctly")
    print("‚úÖ Contexts are consistent between get_context_for_query() and answer()")
    print("‚úÖ Faithfulness scores should vary based on content alignment")
    print("\nüí° If your evaluation still shows 0.5 faithfulness:")
    print("   1. Check that your evaluation framework calls rag.get_context_for_query(query)")
    print("   2. Verify the faithfulness calculation logic in your evaluation code")
    print("   3. Ensure the evaluation uses the returned context, not a reconstructed one")

if __name__ == "__main__":
    test_faithfulness_simulation()
